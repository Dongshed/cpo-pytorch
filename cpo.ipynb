{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs.point_gather import PointGatherEnv\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "from autoassign import autoassign\n",
    "from memory import Memory\n",
    "from models import build_diag_gauss_policy, build_mlp\n",
    "from simulators import SinglePathSimulator\n",
    "from torch_utils.torch_utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt, timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from optimization_utils.conjugate_gradient import cg_solver\n",
    "from torch_utils.distribution_utils import mean_kl_first_fixed\n",
    "from optimization_utils.hvp import get_Hvp_fun\n",
    "from optimization_utils.line_search import line_search\n",
    "from torch_utils.torch_utils import flat_grad, get_device, get_flat_params, normalize, set_params\n",
    "\n",
    "save_dir = 'save-dir'\n",
    "\n",
    "def discount(vals, discount_term):\n",
    "    n = vals.size(0)\n",
    "    disc_pows = torch.pow(discount_term, torch.arange(n).float())\n",
    "    reverse_indxs = torch.arange(n - 1, -1, -1)\n",
    "        \n",
    "    discounted = torch.cumsum((vals * disc_pows)[reverse_indxs], dim=-1)[reverse_indxs] / disc_pows\n",
    "    \n",
    "    return discounted\n",
    "\n",
    "def compute_advs(actual_vals, exp_vals, discount_term, bias_red_param):\n",
    "    exp_vals_next = torch.cat([exp_vals[1:], torch.tensor([0.0])])\n",
    "    td_res = actual_vals + discount_term * exp_vals_next - exp_vals\n",
    "    advs = discount(td_res, discount_term * bias_red_param)\n",
    "    \n",
    "    return advs\n",
    "\n",
    "\n",
    "class CPO:\n",
    "    @autoassign\n",
    "    def __init__(self, policy, value_fun, cost_fun, simulator, max_kl=1e-2, max_val_step=1e-2,\n",
    "                 max_cost_step=1e-2, max_constraint_val=0.1, val_iters=1, cost_iters=1, val_l2_reg=1e-3, \n",
    "                 cost_l2_reg=1e-3, discount_val=0.995, discount_cost=0.995, bias_red_val=0.98, \n",
    "                 bias_red_cost=0.98, cg_damping=1e-3, cg_max_iters=10, line_search_coef=0.9, \n",
    "                 line_search_max_iter=10, line_search_accept_ratio=0.1, model_name=None, \n",
    "                 continue_from_file=False, save_every=5, print_updates=True):\n",
    "        self.mse_loss = MSELoss(reduction='mean')\n",
    "        self.value_optimizer = LBFGS(self.value_fun.parameters(), lr=max_val_step, max_iter=25)\n",
    "        self.cost_optimizer = LBFGS(self.cost_fun.parameters(), lr=max_cost_step, max_iter=25)\n",
    "        self.episode_num = 0\n",
    "        self.elapsed_time = timedelta(0)\n",
    "        self.device = get_device()\n",
    "        self.mean_rewards = []\n",
    "        self.mean_costs = []\n",
    "        \n",
    "        if not model_name and continue_from_file:\n",
    "            raise Exception('Argument continue_from_file to __init__ method of ' \\\n",
    "                            'CPO case was set to True but model_name was not ' \\\n",
    "                            'specified.')\n",
    "\n",
    "        if not model_name and save_every:\n",
    "            raise Exception('Argument save_every to __init__ method of CPO ' \\\n",
    "                            'was set to a value greater than 0 but model_name ' \\\n",
    "                            'was not specified.')\n",
    "\n",
    "        if continue_from_file:\n",
    "            self.load_session()\n",
    "    \n",
    "    def train(self, n_episodes):\n",
    "        states_w_time_prev = None\n",
    "        disc_rewards_prev = None\n",
    "        disc_costs_prev = None\n",
    "        \n",
    "        while self.episode_num < n_episodes:\n",
    "            start_time = dt.now()\n",
    "            self.episode_num += 1\n",
    "            \n",
    "            memory = self.simulator.run_sim()\n",
    "            observations, actions, rewards, costs = memory.sample()\n",
    "            \n",
    "            trajectory_sizes = torch.tensor([len(trajectory) for trajectory in memory])\n",
    "            trajectory_limits = torch.cat([torch.tensor([0]), torch.cumsum(trajectory_sizes, dim=-1)])\n",
    "            N = np.sum([len(trajectory) for trajectory in memory])\n",
    "            T = self.simulator.trajectory_len\n",
    "            time = torch.cat([torch.arange(size).float() for size in trajectory_sizes])\n",
    "            time = torch.unsqueeze(time, dim=1) / T\n",
    "            states_w_time = torch.cat([observations, time], dim=1)\n",
    "            \n",
    "            disc_rewards = torch.zeros(N)\n",
    "            disc_costs = torch.zeros(N)\n",
    "            reward_advs = torch.zeros(N)\n",
    "            cost_advs = torch.zeros(N)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                state_vals = self.value_fun(states_w_time.to(self.device)).view(-1).cpu()\n",
    "                state_costs = self.cost_fun(states_w_time.to(self.device)).view(-1).cpu()\n",
    "            \n",
    "            for start, end in zip(trajectory_limits[:-1], trajectory_limits[1:]):\n",
    "                disc_rewards[start:end] = discount(rewards[start:end], self.discount_val)\n",
    "                disc_costs[start:end] = discount(costs[start:end], self.discount_cost)\n",
    "                reward_advs[start:end] = compute_advs(rewards[start:end],\n",
    "                                                      state_vals[start:end],\n",
    "                                                      self.discount_val,\n",
    "                                                      self.bias_red_val)\n",
    "                cost_advs[start:end] = compute_advs(costs[start:end],\n",
    "                                                    state_costs[start:end],\n",
    "                                                    self.discount_cost,\n",
    "                                                    self.bias_red_cost)\n",
    "             \n",
    "            reward_advs -= reward_advs.mean()\n",
    "            reward_advs /= reward_advs.std()\n",
    "            cost_advs -= reward_advs.mean()\n",
    "            cost_advs /= cost_advs.std()\n",
    "            \n",
    "            if states_w_time_prev is not None:\n",
    "                states_w_time_train = torch.cat([states_w_time, states_w_time_prev])\n",
    "                disc_rewards_train = torch.cat([disc_rewards, disc_rewards_prev])\n",
    "                disc_costs_train = torch.cat([disc_costs, disc_costs_prev])\n",
    "            else:\n",
    "                states_w_time_train = states_w_time\n",
    "                disc_rewards_train = disc_rewards\n",
    "                disc_costs_train = disc_costs\n",
    "                \n",
    "            states_w_time_prev = states_w_time\n",
    "            disc_rewards_prev = disc_rewards\n",
    "            disc_costs_prev = disc_costs\n",
    "            \n",
    "#             constraint_cost = torch.mean(torch.tensor([disc_costs[start] for start in trajectory_limits[:-1]]))\n",
    "            constraint_cost = torch.mean(torch.tensor([torch.sum(torch.tensor(trajectory.costs))\n",
    "                                                       for trajectory in memory]))\n",
    "    \n",
    "            self.update_policy(observations, actions, reward_advs, cost_advs, constraint_cost)\n",
    "            self.update_nn_regressor(self.value_fun, self.value_optimizer, states_w_time_train,\n",
    "                                     disc_rewards_train, self.val_l2_reg, self.val_iters)\n",
    "            self.update_nn_regressor(self.cost_fun, self.cost_optimizer, states_w_time_train,\n",
    "                                     disc_costs_train, self.cost_l2_reg, self.cost_iters)\n",
    "            \n",
    "            reward_sums = [np.sum(trajectory.rewards) for trajectory in memory]\n",
    "            cost_sums = [np.sum(trajectory.costs) for trajectory in memory]\n",
    "            self.mean_rewards.append(np.mean(reward_sums))\n",
    "            self.mean_costs.append(np.mean(cost_sums))\n",
    "            self.elapsed_time += dt.now() - start_time\n",
    "\n",
    "            if self.print_updates:\n",
    "                self.print_update()\n",
    "\n",
    "            if self.save_every and not self.episode_num % self.save_every:\n",
    "                self.save_session()\n",
    "    \n",
    "    def update_policy(self, observations, actions, reward_advs, constraint_advs, J_c):\n",
    "        self.policy.train()\n",
    "        \n",
    "        observations = observations.to(self.device)\n",
    "        actions = actions.to(self.device)\n",
    "        reward_advs = reward_advs.to(self.device)\n",
    "        constraint_advs = constraint_advs.to(self.device)\n",
    "        \n",
    "        action_dists = self.policy(observations)\n",
    "        log_action_probs = action_dists.log_prob(actions)\n",
    "        \n",
    "        imp_sampling = torch.exp(log_action_probs - log_action_probs.detach())\n",
    "        # Change to torch.matmul\n",
    "        reward_loss = -torch.mean(imp_sampling * reward_advs)\n",
    "        reward_grad = flat_grad(reward_loss, self.policy.parameters(), retain_graph=True)\n",
    "        # Change to torch.matmul\n",
    "        constraint_loss = torch.sum(imp_sampling * constraint_advs) / self.simulator.n_trajectories\n",
    "        constraint_grad = flat_grad(constraint_loss, self.policy.parameters(), retain_graph=True)\n",
    "        \n",
    "        mean_kl = mean_kl_first_fixed(action_dists, action_dists)\n",
    "        Fvp_fun = get_Hvp_fun(mean_kl, self.policy.parameters())\n",
    "    \n",
    "        F_inv_g = cg_solver(Fvp_fun, reward_grad)\n",
    "        F_inv_b = cg_solver(Fvp_fun, constraint_grad)\n",
    "        \n",
    "        q = torch.matmul(reward_grad, F_inv_g)\n",
    "        r = torch.matmul(reward_grad, F_inv_b)\n",
    "        s = torch.matmul(constraint_grad, F_inv_b)\n",
    "        c = (J_c - self.max_constraint_val).to(self.device)\n",
    "            \n",
    "        is_feasible = False if c > 0 and c ** 2 / s - 2 * self.max_kl > 0 else True\n",
    "       \n",
    "        if is_feasible:\n",
    "            lam, nu = self.calc_dual_vars(q, r, s, c)\n",
    "#             print('\\nlam: ', lam)\n",
    "#             print('nu: ', nu, '\\n')\n",
    "            search_dir = -lam ** -1 * (F_inv_g + nu * F_inv_b)\n",
    "        else:\n",
    "            # Recovery update\n",
    "#             print('RECOVERY MODE')\n",
    "            search_dir = -torch.sqrt(2 * self.max_kl / s) * F_inv_b\n",
    "        \n",
    "        # Should be positive\n",
    "        exp_loss_improv = torch.matmul(reward_grad, search_dir)\n",
    "        \n",
    "#         print('Expected reward improv.:', exp_loss_improv)\n",
    "#         print('Expected cost improv.:', torch.matmul(constraint_grad, search_dir))\n",
    "        \n",
    "        current_policy = get_flat_params(self.policy)\n",
    "        \n",
    "        def line_search_criterion(search_dir, step_len):\n",
    "            test_policy = current_policy + step_len * search_dir\n",
    "            set_params(self.policy, test_policy)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Test if conditions are satisfied\n",
    "                test_dists = self.policy(observations)\n",
    "                test_probs = test_dists.log_prob(actions)\n",
    "                \n",
    "                imp_sampling = torch.exp(test_probs - log_action_probs.detach())\n",
    "                \n",
    "                test_loss = -torch.mean(imp_sampling * reward_advs)\n",
    "                test_cost = torch.sum(imp_sampling * constraint_advs) / self.simulator.n_trajectories\n",
    "                test_kl = mean_kl_first_fixed(action_dists, test_dists)\n",
    "                \n",
    "                print(step_len * torch.matmul(constraint_grad, search_dir), -c)\n",
    "                \n",
    "#                 loss_improv_cond = test_loss <= reward_loss\n",
    "                loss_improv_cond = (test_loss - reward_loss) / (step_len * exp_loss_improv) >= self.line_search_accept_ratio\n",
    "                cost_cond = step_len * torch.matmul(constraint_grad, search_dir) <= max(-c, 0.0)\n",
    "#                 cost_cond = test_cost <= constraint_loss\n",
    "                kl_cond = test_kl <= self.max_kl\n",
    "                            \n",
    "            set_params(self.policy, current_policy)\n",
    "            \n",
    "            if is_feasible:\n",
    "                return loss_improv_cond and cost_cond and kl_cond\n",
    "            \n",
    "            return cost_cond and kl_cond\n",
    "        \n",
    "        step_len = line_search(search_dir, 1.0, line_search_criterion, self.line_search_coef)\n",
    "        print('Step Len.:', step_len, '\\n')\n",
    "        new_policy = current_policy + step_len * search_dir\n",
    "        set_params(self.policy, new_policy)\n",
    "            \n",
    "    def update_nn_regressor(self, nn_regressor, optimizer, states, targets, l2_reg_coef, n_iters=1):\n",
    "        nn_regressor.train()\n",
    "        \n",
    "        states = states.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "        \n",
    "        for _ in range(n_iters):\n",
    "            def mse():\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                predictions = nn_regressor(states).view(-1)\n",
    "                loss = self.mse_loss(predictions, targets)\n",
    "                \n",
    "                flat_params = get_flat_params(nn_regressor)\n",
    "                l2_loss = l2_reg_coef * torch.sum(torch.pow(flat_params, 2))\n",
    "                loss += l2_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                return loss\n",
    "            \n",
    "            optimizer.step(mse)\n",
    "    \n",
    "    def calc_dual_vars(self, q, r, s, c):\n",
    "        if c < 0.0 and c ** 2 / s - 2 * self.max_kl > 0.0:\n",
    "            lam = torch.sqrt(q / (2 * self.max_kl))\n",
    "            nu = 0.0\n",
    "            \n",
    "            return lam, nu\n",
    "        \n",
    "        A = q - r ** 2 / s\n",
    "        B = 2 * self.max_kl - c ** 2 / s\n",
    "\n",
    "        lam_mid = r / c\n",
    "        lam_a = torch.sqrt(A / B)\n",
    "        lam_b = torch.sqrt(q / (2 * self.max_kl))\n",
    "        \n",
    "        f_mid = -0.5 * (q / lam_mid + 2 * lam_mid * self.max_kl)\n",
    "        f_a = -torch.sqrt(A * B) - r * c / s\n",
    "        f_b = -torch.sqrt(2 * q * self.max_kl)\n",
    "    \n",
    "        if lam_mid > 0:\n",
    "            if c < 0:\n",
    "                if lam_a > lam_mid:\n",
    "                    lam_a = lam_mid\n",
    "                    f_a = f_mid\n",
    "                if lam_b < lam_mid:\n",
    "                    lam_b = lam_mid\n",
    "                    f_b = f_mid\n",
    "            else:\n",
    "                if lam_a < lam_mid:\n",
    "                    lam_a = lam_mid\n",
    "                    f_a = f_mid\n",
    "                if lam_b > lam_mid:\n",
    "                    lam_b = lam_mid\n",
    "                    f_b = f_mid\n",
    "        else:\n",
    "            if c < 0:\n",
    "                lam = lam_b\n",
    "            else:\n",
    "                lam = lam_a\n",
    "        \n",
    "        lam = lam_a if f_a >= f_b else lam_b\n",
    "        nu = max(0.0, (lam * c - r) / s)\n",
    "        \n",
    "        return lam, nu\n",
    "    \n",
    "    def save_session(self):\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "            \n",
    "        save_path = os.path.join(save_dir, self.model_name + '.pt')\n",
    "        \n",
    "        ckpt = dict(policy_state_dict=self.policy.state_dict(),\n",
    "                    value_state_dict=self.value_fun.state_dict(),\n",
    "                    cost_state_dict=self.cost_fun.state_dict(),\n",
    "                    mean_rewards=self.mean_rewards,\n",
    "                    mean_costs=self.mean_costs,\n",
    "                    episode_num=self.episode_num,\n",
    "                    elapsed_time=self.elapsed_time)\n",
    "        \n",
    "        if self.simulator.obs_filter:\n",
    "            ckpt['obs_filter'] = self.simulator.obs_filter\n",
    "            \n",
    "        torch.save(ckpt, save_path)\n",
    "    \n",
    "    def load_session(self):\n",
    "        load_path = os.path.join(save_dir, self.model_name + '.pt')\n",
    "        ckpt = torch.load(load_path)\n",
    "        \n",
    "        self.policy.load_state_dict(ckpt['policy_state_dict'])\n",
    "        self.value_fun.load_state_dict(ckpt['value_state_dict'])\n",
    "        self.cost_fun.load_state_dict(ckpt['cost_state_dict'])\n",
    "        self.mean_rewards = ckpt['mean_rewards']\n",
    "        self.mean_costs = ckpt['mean_costs']\n",
    "        self.episode_num = ckpt['episode_num']\n",
    "        self.elapsed_time = ckpt['elapsed_time']\n",
    "        \n",
    "        try:\n",
    "            self.simulator.obs_filter = ckpt['obs_filter']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    def print_update(self):\n",
    "        update_message = '[Episode]: {0} | [Avg. Reward]: {1} | [Avg. Cost]: {2} | [Elapsed Time]: {3}'\n",
    "        elapsed_time_str = ''.join(str(self.elapsed_time)).split('.')[0]\n",
    "        format_args = (self.episode_num, self.mean_rewards[-1], self.mean_costs[-1], elapsed_time_str)\n",
    "        print(update_message.format(*format_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 29\n",
    "action_dim = 2\n",
    "hidden_dims = [64, 32]\n",
    "n_trajectories = 25000\n",
    "trajectory_len = 16\n",
    "device = get_device()\n",
    "\n",
    "policy = build_diag_gauss_policy(state_dim, hidden_dims, action_dim)\n",
    "value_fun = build_mlp(state_dim + 1, hidden_dims, 1)\n",
    "cost_fun = build_mlp(state_dim + 1, hidden_dims, 1)\n",
    "\n",
    "policy.to(device)\n",
    "value_fun.to(device)\n",
    "cost_fun.to(device)\n",
    "\n",
    "simulator = SinglePathSimulator('point-gather', policy, n_trajectories, trajectory_len)\n",
    "\n",
    "cpo = CPO(policy, value_fun, cost_fun, simulator, model_name='point-gather', bias_red_cost=1.0, max_constraint_val=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderlangley/Desktop/cpo-pytorch/simulators.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  for trajectory in trajs_to_update])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2166, device='cuda:0') tensor(-0.5014, device='cuda:0')\n",
      "tensor(-0.1755, device='cuda:0') tensor(-0.5014, device='cuda:0')\n",
      "tensor(-0.1421, device='cuda:0') tensor(-0.5014, device='cuda:0')\n",
      "tensor(-0.1151, device='cuda:0') tensor(-0.5014, device='cuda:0')\n",
      "Step Len.: 0.7290000000000001 \n",
      "\n",
      "[Episode]: 1 | [Avg. Reward]: 5.397759914398193 | [Avg. Cost]: 0.6014400124549866 | [Elapsed Time]: 0:04:24\n",
      "tensor(-0.2395, device='cuda:0') tensor(-0.4079, device='cuda:0')\n",
      "tensor(-0.1940, device='cuda:0') tensor(-0.4079, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 2 | [Avg. Reward]: 5.378479957580566 | [Avg. Cost]: 0.5079200267791748 | [Elapsed Time]: 0:08:01\n",
      "tensor(-0.2232, device='cuda:0') tensor(-0.2968, device='cuda:0')\n",
      "tensor(-0.1808, device='cuda:0') tensor(-0.2968, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 3 | [Avg. Reward]: 5.084839820861816 | [Avg. Cost]: 0.3967599868774414 | [Elapsed Time]: 0:16:24\n",
      "tensor(-0.2034, device='cuda:0') tensor(-0.2100, device='cuda:0')\n",
      "tensor(-0.1648, device='cuda:0') tensor(-0.2100, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 4 | [Avg. Reward]: 4.91595983505249 | [Avg. Cost]: 0.3100399971008301 | [Elapsed Time]: 0:20:06\n",
      "tensor(-0.1350, device='cuda:0') tensor(-0.1358, device='cuda:0')\n",
      "tensor(-0.1093, device='cuda:0') tensor(-0.1358, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 5 | [Avg. Reward]: 4.640200138092041 | [Avg. Cost]: 0.23579999804496765 | [Elapsed Time]: 0:23:54\n",
      "tensor(-0.1086, device='cuda:0') tensor(-0.1070, device='cuda:0')\n",
      "tensor(-0.0880, device='cuda:0') tensor(-0.1070, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 6 | [Avg. Reward]: 5.119359970092773 | [Avg. Cost]: 0.2070399969816208 | [Elapsed Time]: 0:27:56\n",
      "tensor(-0.0863, device='cuda:0') tensor(-0.0841, device='cuda:0')\n",
      "tensor(-0.0699, device='cuda:0') tensor(-0.0841, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 7 | [Avg. Reward]: 5.741519927978516 | [Avg. Cost]: 0.18408000469207764 | [Elapsed Time]: 0:31:58\n",
      "tensor(-0.0579, device='cuda:0') tensor(-0.0600, device='cuda:0')\n",
      "tensor(-0.0469, device='cuda:0') tensor(-0.0600, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 8 | [Avg. Reward]: 6.4120402336120605 | [Avg. Cost]: 0.15996000170707703 | [Elapsed Time]: 0:36:01\n",
      "tensor(-0.0449, device='cuda:0') tensor(-0.0506, device='cuda:0')\n",
      "tensor(-0.0364, device='cuda:0') tensor(-0.0506, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 9 | [Avg. Reward]: 6.9822001457214355 | [Avg. Cost]: 0.15060000121593475 | [Elapsed Time]: 0:40:02\n",
      "tensor(-0.0314, device='cuda:0') tensor(-0.0443, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 10 | [Avg. Reward]: 7.702119827270508 | [Avg. Cost]: 0.14428000152111053 | [Elapsed Time]: 0:44:05\n",
      "tensor(-0.0320, device='cuda:0') tensor(-0.0396, device='cuda:0')\n",
      "tensor(-0.0259, device='cuda:0') tensor(-0.0396, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 11 | [Avg. Reward]: 8.47916030883789 | [Avg. Cost]: 0.13964000344276428 | [Elapsed Time]: 0:52:40\n",
      "tensor(-0.0174, device='cuda:0') tensor(-0.0338, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 12 | [Avg. Reward]: 9.486160278320312 | [Avg. Cost]: 0.13383999466896057 | [Elapsed Time]: 0:56:41\n",
      "tensor(-0.0148, device='cuda:0') tensor(-0.0333, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 13 | [Avg. Reward]: 10.42788028717041 | [Avg. Cost]: 0.13332000374794006 | [Elapsed Time]: 1:00:42\n",
      "tensor(-0.0141, device='cuda:0') tensor(-0.0328, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 14 | [Avg. Reward]: 11.356439590454102 | [Avg. Cost]: 0.13276000320911407 | [Elapsed Time]: 1:04:44\n",
      "tensor(-0.0177, device='cuda:0') tensor(-0.0298, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 15 | [Avg. Reward]: 12.450639724731445 | [Avg. Cost]: 0.1297599971294403 | [Elapsed Time]: 1:08:47\n",
      "tensor(-0.0263, device='cuda:0') tensor(-0.0276, device='cuda:0')\n",
      "tensor(-0.0213, device='cuda:0') tensor(-0.0276, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 16 | [Avg. Reward]: 13.422800064086914 | [Avg. Cost]: 0.12759999930858612 | [Elapsed Time]: 1:12:50\n",
      "tensor(-0.0192, device='cuda:0') tensor(-0.0248, device='cuda:0')\n",
      "tensor(-0.0155, device='cuda:0') tensor(-0.0248, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 17 | [Avg. Reward]: 14.324399948120117 | [Avg. Cost]: 0.12479999661445618 | [Elapsed Time]: 1:16:53\n",
      "tensor(-0.0369, device='cuda:0') tensor(-0.0241, device='cuda:0')\n",
      "tensor(-0.0299, device='cuda:0') tensor(-0.0241, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 18 | [Avg. Reward]: 15.163519859313965 | [Avg. Cost]: 0.12408000230789185 | [Elapsed Time]: 1:20:55\n",
      "tensor(-0.0117, device='cuda:0') tensor(-0.0151, device='cuda:0')\n",
      "tensor(-0.0095, device='cuda:0') tensor(-0.0151, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 19 | [Avg. Reward]: 15.63047981262207 | [Avg. Cost]: 0.11512000113725662 | [Elapsed Time]: 1:29:42\n",
      "tensor(-0.0193, device='cuda:0') tensor(-0.0120, device='cuda:0')\n",
      "tensor(-0.0156, device='cuda:0') tensor(-0.0120, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 20 | [Avg. Reward]: 16.458799362182617 | [Avg. Cost]: 0.1120000034570694 | [Elapsed Time]: 1:33:40\n",
      "tensor(-0.0173, device='cuda:0') tensor(-0.0110, device='cuda:0')\n",
      "tensor(-0.0140, device='cuda:0') tensor(-0.0110, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 21 | [Avg. Reward]: 17.04863929748535 | [Avg. Cost]: 0.11095999926328659 | [Elapsed Time]: 1:37:42\n",
      "tensor(-0.0161, device='cuda:0') tensor(-0.0117, device='cuda:0')\n",
      "tensor(-0.0130, device='cuda:0') tensor(-0.0117, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 22 | [Avg. Reward]: 17.704679489135742 | [Avg. Cost]: 0.1117200031876564 | [Elapsed Time]: 1:41:43\n",
      "tensor(-0.0184, device='cuda:0') tensor(-0.0130, device='cuda:0')\n",
      "tensor(-0.0149, device='cuda:0') tensor(-0.0130, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 23 | [Avg. Reward]: 18.238239288330078 | [Avg. Cost]: 0.11296000331640244 | [Elapsed Time]: 1:45:43\n",
      "tensor(-0.0090, device='cuda:0') tensor(-0.0066, device='cuda:0')\n",
      "tensor(-0.0073, device='cuda:0') tensor(-0.0066, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 24 | [Avg. Reward]: 18.764999389648438 | [Avg. Cost]: 0.10660000145435333 | [Elapsed Time]: 1:49:43\n",
      "tensor(-0.0064, device='cuda:0') tensor(-0.0060, device='cuda:0')\n",
      "tensor(-0.0052, device='cuda:0') tensor(-0.0060, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 25 | [Avg. Reward]: 19.330360412597656 | [Avg. Cost]: 0.10604000091552734 | [Elapsed Time]: 1:53:42\n",
      "tensor(-0.0087, device='cuda:0') tensor(-0.0052, device='cuda:0')\n",
      "tensor(-0.0070, device='cuda:0') tensor(-0.0052, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 26 | [Avg. Reward]: 19.75480079650879 | [Avg. Cost]: 0.10520000010728836 | [Elapsed Time]: 1:57:41\n",
      "tensor(-0.0088, device='cuda:0') tensor(-0.0114, device='cuda:0')\n",
      "tensor(-0.0072, device='cuda:0') tensor(-0.0114, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 27 | [Avg. Reward]: 20.231800079345703 | [Avg. Cost]: 0.11140000075101852 | [Elapsed Time]: 2:01:42\n",
      "tensor(-0.0134, device='cuda:0') tensor(-0.0097, device='cuda:0')\n",
      "tensor(-0.0108, device='cuda:0') tensor(-0.0097, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 28 | [Avg. Reward]: 20.73348045349121 | [Avg. Cost]: 0.10971999913454056 | [Elapsed Time]: 2:10:07\n",
      "tensor(-0.0132, device='cuda:0') tensor(-0.0107, device='cuda:0')\n",
      "tensor(-0.0107, device='cuda:0') tensor(-0.0107, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 29 | [Avg. Reward]: 20.95008087158203 | [Avg. Cost]: 0.11072000116109848 | [Elapsed Time]: 2:14:03\n",
      "tensor(-0.0088, device='cuda:0') tensor(-0.0086, device='cuda:0')\n",
      "tensor(-0.0071, device='cuda:0') tensor(-0.0086, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 30 | [Avg. Reward]: 21.290639877319336 | [Avg. Cost]: 0.1085600033402443 | [Elapsed Time]: 2:18:01\n",
      "tensor(-0.0090, device='cuda:0') tensor(-0.0076, device='cuda:0')\n",
      "tensor(-0.0073, device='cuda:0') tensor(-0.0076, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 31 | [Avg. Reward]: 21.76483917236328 | [Avg. Cost]: 0.10756000131368637 | [Elapsed Time]: 2:21:58\n",
      "tensor(-0.0113, device='cuda:0') tensor(-0.0120, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 32 | [Avg. Reward]: 22.0987606048584 | [Avg. Cost]: 0.11203999817371368 | [Elapsed Time]: 2:25:56\n",
      "tensor(-0.0184, device='cuda:0') tensor(-0.0134, device='cuda:0')\n",
      "tensor(-0.0149, device='cuda:0') tensor(-0.0134, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 33 | [Avg. Reward]: 22.44144058227539 | [Avg. Cost]: 0.11336000263690948 | [Elapsed Time]: 2:29:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0122, device='cuda:0') tensor(-0.0126, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 34 | [Avg. Reward]: 22.847440719604492 | [Avg. Cost]: 0.11255999654531479 | [Elapsed Time]: 2:33:54\n",
      "tensor(-0.0174, device='cuda:0') tensor(-0.0114, device='cuda:0')\n",
      "tensor(-0.0141, device='cuda:0') tensor(-0.0114, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 35 | [Avg. Reward]: 23.063440322875977 | [Avg. Cost]: 0.11135999858379364 | [Elapsed Time]: 2:37:53\n",
      "tensor(-0.0163, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 36 | [Avg. Reward]: 23.348800659179688 | [Avg. Cost]: 0.11400000005960464 | [Elapsed Time]: 2:46:28\n",
      "tensor(-0.0188, device='cuda:0') tensor(-0.0154, device='cuda:0')\n",
      "tensor(-0.0152, device='cuda:0') tensor(-0.0154, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 37 | [Avg. Reward]: 23.639400482177734 | [Avg. Cost]: 0.11540000140666962 | [Elapsed Time]: 2:50:23\n",
      "tensor(-0.0108, device='cuda:0') tensor(-0.0156, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 38 | [Avg. Reward]: 23.935640335083008 | [Avg. Cost]: 0.11556000262498856 | [Elapsed Time]: 2:54:23\n",
      "tensor(-0.0228, device='cuda:0') tensor(-0.0163, device='cuda:0')\n",
      "tensor(-0.0184, device='cuda:0') tensor(-0.0163, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 39 | [Avg. Reward]: 24.352479934692383 | [Avg. Cost]: 0.11631999909877777 | [Elapsed Time]: 2:58:23\n",
      "tensor(-0.0201, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "tensor(-0.0163, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 40 | [Avg. Reward]: 24.421199798583984 | [Avg. Cost]: 0.11400000005960464 | [Elapsed Time]: 3:02:25\n",
      "tensor(-0.0135, device='cuda:0') tensor(-0.0106, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 41 | [Avg. Reward]: 24.574600219726562 | [Avg. Cost]: 0.11060000211000443 | [Elapsed Time]: 3:06:22\n",
      "tensor(-0.0231, device='cuda:0') tensor(-0.0166, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 42 | [Avg. Reward]: 24.926240921020508 | [Avg. Cost]: 0.11655999720096588 | [Elapsed Time]: 3:10:20\n",
      "tensor(-0.0188, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 43 | [Avg. Reward]: 25.037200927734375 | [Avg. Cost]: 0.11400000005960464 | [Elapsed Time]: 3:14:19\n",
      "tensor(-0.0183, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 44 | [Avg. Reward]: 25.302400588989258 | [Avg. Cost]: 0.11400000005960464 | [Elapsed Time]: 3:22:53\n",
      "tensor(-0.0149, device='cuda:0') tensor(-0.0151, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 45 | [Avg. Reward]: 25.565319061279297 | [Avg. Cost]: 0.11507999897003174 | [Elapsed Time]: 3:26:47\n",
      "tensor(-0.0108, device='cuda:0') tensor(-0.0129, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 46 | [Avg. Reward]: 25.7802791595459 | [Avg. Cost]: 0.11292000114917755 | [Elapsed Time]: 3:30:42\n",
      "tensor(-0.0167, device='cuda:0') tensor(-0.0138, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 47 | [Avg. Reward]: 25.89504051208496 | [Avg. Cost]: 0.11376000195741653 | [Elapsed Time]: 3:34:38\n",
      "tensor(-0.0210, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "tensor(-0.0170, device='cuda:0') tensor(-0.0140, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 48 | [Avg. Reward]: 26.24675941467285 | [Avg. Cost]: 0.11404000222682953 | [Elapsed Time]: 3:38:35\n",
      "tensor(-0.0158, device='cuda:0') tensor(-0.0170, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 49 | [Avg. Reward]: 26.404640197753906 | [Avg. Cost]: 0.11695999652147293 | [Elapsed Time]: 3:42:32\n",
      "tensor(-0.0136, device='cuda:0') tensor(-0.0149, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 50 | [Avg. Reward]: 26.34827995300293 | [Avg. Cost]: 0.1149199977517128 | [Elapsed Time]: 3:46:31\n",
      "tensor(-0.0185, device='cuda:0') tensor(-0.0167, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 51 | [Avg. Reward]: 26.611679077148438 | [Avg. Cost]: 0.11671999841928482 | [Elapsed Time]: 3:50:29\n",
      "tensor(-0.0241, device='cuda:0') tensor(-0.0190, device='cuda:0')\n",
      "tensor(-0.0195, device='cuda:0') tensor(-0.0190, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 52 | [Avg. Reward]: 26.768999099731445 | [Avg. Cost]: 0.11900000274181366 | [Elapsed Time]: 3:54:28\n",
      "tensor(-0.0216, device='cuda:0') tensor(-0.0183, device='cuda:0')\n",
      "tensor(-0.0175, device='cuda:0') tensor(-0.0183, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 53 | [Avg. Reward]: 26.950519561767578 | [Avg. Cost]: 0.11828000098466873 | [Elapsed Time]: 4:02:51\n",
      "tensor(-0.0153, device='cuda:0') tensor(-0.0154, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 54 | [Avg. Reward]: 27.01144027709961 | [Avg. Cost]: 0.11535999923944473 | [Elapsed Time]: 4:06:43\n",
      "tensor(-0.0202, device='cuda:0') tensor(-0.0151, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 55 | [Avg. Reward]: 27.144479751586914 | [Avg. Cost]: 0.11512000113725662 | [Elapsed Time]: 4:10:41\n",
      "tensor(-0.0157, device='cuda:0') tensor(-0.0154, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 56 | [Avg. Reward]: 27.201839447021484 | [Avg. Cost]: 0.11535999923944473 | [Elapsed Time]: 4:14:37\n",
      "tensor(-0.0078, device='cuda:0') tensor(-0.0115, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 57 | [Avg. Reward]: 27.18008041381836 | [Avg. Cost]: 0.11151999980211258 | [Elapsed Time]: 4:18:34\n",
      "tensor(-0.0053, device='cuda:0') tensor(-0.0186, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 58 | [Avg. Reward]: 27.392200469970703 | [Avg. Cost]: 0.11860000342130661 | [Elapsed Time]: 4:22:31\n",
      "tensor(-0.0265, device='cuda:0') tensor(-0.0200, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 59 | [Avg. Reward]: 27.52164077758789 | [Avg. Cost]: 0.1199600026011467 | [Elapsed Time]: 4:26:28\n",
      "tensor(-0.0117, device='cuda:0') tensor(-0.0158, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 60 | [Avg. Reward]: 27.631040573120117 | [Avg. Cost]: 0.11575999855995178 | [Elapsed Time]: 4:30:26\n",
      "tensor(-0.0269, device='cuda:0') tensor(-0.0198, device='cuda:0')\n",
      "tensor(-0.0218, device='cuda:0') tensor(-0.0198, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 61 | [Avg. Reward]: 27.73975944519043 | [Avg. Cost]: 0.11984000355005264 | [Elapsed Time]: 4:39:01\n",
      "tensor(-0.0256, device='cuda:0') tensor(-0.0162, device='cuda:0')\n",
      "tensor(-0.0207, device='cuda:0') tensor(-0.0162, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 62 | [Avg. Reward]: 27.684240341186523 | [Avg. Cost]: 0.11615999788045883 | [Elapsed Time]: 4:42:56\n",
      "tensor(-0.0189, device='cuda:0') tensor(-0.0166, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 63 | [Avg. Reward]: 27.756559371948242 | [Avg. Cost]: 0.11664000153541565 | [Elapsed Time]: 4:46:55\n",
      "tensor(-0.0223, device='cuda:0') tensor(-0.0196, device='cuda:0')\n",
      "tensor(-0.0180, device='cuda:0') tensor(-0.0196, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 64 | [Avg. Reward]: 27.985559463500977 | [Avg. Cost]: 0.11964000016450882 | [Elapsed Time]: 4:50:53\n",
      "tensor(-0.0264, device='cuda:0') tensor(-0.0182, device='cuda:0')\n",
      "tensor(-0.0214, device='cuda:0') tensor(-0.0182, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 65 | [Avg. Reward]: 28.025840759277344 | [Avg. Cost]: 0.11816000193357468 | [Elapsed Time]: 4:54:52\n",
      "tensor(-0.0092, device='cuda:0') tensor(-0.0128, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 66 | [Avg. Reward]: 28.02716064453125 | [Avg. Cost]: 0.11283999681472778 | [Elapsed Time]: 4:59:13\n",
      "tensor(-0.0263, device='cuda:0') tensor(-0.0203, device='cuda:0')\n",
      "tensor(-0.0213, device='cuda:0') tensor(-0.0203, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 67 | [Avg. Reward]: 28.262880325317383 | [Avg. Cost]: 0.12031999975442886 | [Elapsed Time]: 5:03:18\n",
      "tensor(-0.0204, device='cuda:0') tensor(-0.0150, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 68 | [Avg. Reward]: 28.438199996948242 | [Avg. Cost]: 0.11500000208616257 | [Elapsed Time]: 5:07:18\n",
      "tensor(-0.0231, device='cuda:0') tensor(-0.0136, device='cuda:0')\n",
      "tensor(-0.0187, device='cuda:0') tensor(-0.0136, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 69 | [Avg. Reward]: 28.317960739135742 | [Avg. Cost]: 0.11364000290632248 | [Elapsed Time]: 5:15:58\n",
      "tensor(-0.0121, device='cuda:0') tensor(-0.0096, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 70 | [Avg. Reward]: 28.465240478515625 | [Avg. Cost]: 0.10955999791622162 | [Elapsed Time]: 5:19:59\n",
      "tensor(-0.0141, device='cuda:0') tensor(-0.0194, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 71 | [Avg. Reward]: 28.58095932006836 | [Avg. Cost]: 0.119439996778965 | [Elapsed Time]: 5:24:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0211, device='cuda:0') tensor(-0.0180, device='cuda:0')\n",
      "tensor(-0.0171, device='cuda:0') tensor(-0.0180, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 72 | [Avg. Reward]: 28.60964012145996 | [Avg. Cost]: 0.11795999854803085 | [Elapsed Time]: 5:28:03\n",
      "tensor(-0.0210, device='cuda:0') tensor(-0.0227, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 73 | [Avg. Reward]: 28.69331932067871 | [Avg. Cost]: 0.12268000096082687 | [Elapsed Time]: 5:32:00\n",
      "tensor(-0.0134, device='cuda:0') tensor(-0.0130, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 74 | [Avg. Reward]: 28.754959106445312 | [Avg. Cost]: 0.1130400002002716 | [Elapsed Time]: 5:35:56\n",
      "tensor(-0.0168, device='cuda:0') tensor(-0.0187, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 75 | [Avg. Reward]: 28.920879364013672 | [Avg. Cost]: 0.11872000247240067 | [Elapsed Time]: 5:39:53\n",
      "tensor(-0.0208, device='cuda:0') tensor(-0.0192, device='cuda:0')\n",
      "tensor(-0.0169, device='cuda:0') tensor(-0.0192, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 76 | [Avg. Reward]: 29.091960906982422 | [Avg. Cost]: 0.11924000084400177 | [Elapsed Time]: 5:43:51\n",
      "tensor(-0.0203, device='cuda:0') tensor(-0.0199, device='cuda:0')\n",
      "tensor(-0.0165, device='cuda:0') tensor(-0.0199, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 77 | [Avg. Reward]: 28.978919982910156 | [Avg. Cost]: 0.11987999826669693 | [Elapsed Time]: 5:47:49\n",
      "tensor(-0.0345, device='cuda:0') tensor(-0.0153, device='cuda:0')\n",
      "tensor(-0.0279, device='cuda:0') tensor(-0.0153, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 78 | [Avg. Reward]: 29.045879364013672 | [Avg. Cost]: 0.11531999707221985 | [Elapsed Time]: 5:56:12\n",
      "tensor(-0.0133, device='cuda:0') tensor(-0.0118, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 79 | [Avg. Reward]: 29.006200790405273 | [Avg. Cost]: 0.11180000007152557 | [Elapsed Time]: 6:00:04\n",
      "tensor(-0.0171, device='cuda:0') tensor(-0.0160, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 80 | [Avg. Reward]: 29.09756088256836 | [Avg. Cost]: 0.11603999882936478 | [Elapsed Time]: 6:04:00\n",
      "tensor(-0.0258, device='cuda:0') tensor(-0.0182, device='cuda:0')\n",
      "tensor(-0.0209, device='cuda:0') tensor(-0.0182, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 81 | [Avg. Reward]: 29.28619956970215 | [Avg. Cost]: 0.11819999665021896 | [Elapsed Time]: 6:07:56\n",
      "tensor(-0.0120, device='cuda:0') tensor(-0.0173, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 82 | [Avg. Reward]: 29.180320739746094 | [Avg. Cost]: 0.11727999895811081 | [Elapsed Time]: 6:11:55\n",
      "tensor(-0.0146, device='cuda:0') tensor(-0.0160, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 83 | [Avg. Reward]: 29.303239822387695 | [Avg. Cost]: 0.1159600019454956 | [Elapsed Time]: 6:15:50\n",
      "tensor(-0.0126, device='cuda:0') tensor(-0.0159, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 84 | [Avg. Reward]: 29.343320846557617 | [Avg. Cost]: 0.11587999761104584 | [Elapsed Time]: 6:19:46\n",
      "tensor(-0.0229, device='cuda:0') tensor(-0.0198, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 85 | [Avg. Reward]: 29.390199661254883 | [Avg. Cost]: 0.11980000138282776 | [Elapsed Time]: 6:23:44\n",
      "tensor(-0.0114, device='cuda:0') tensor(-0.0177, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 86 | [Avg. Reward]: 29.27672004699707 | [Avg. Cost]: 0.11767999827861786 | [Elapsed Time]: 6:32:16\n",
      "tensor(-0.0226, device='cuda:0') tensor(-0.0248, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 87 | [Avg. Reward]: 29.666799545288086 | [Avg. Cost]: 0.12479999661445618 | [Elapsed Time]: 6:36:09\n",
      "tensor(-0.0186, device='cuda:0') tensor(-0.0228, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 88 | [Avg. Reward]: 29.58679962158203 | [Avg. Cost]: 0.12280000001192093 | [Elapsed Time]: 6:40:08\n",
      "tensor(-0.0246, device='cuda:0') tensor(-0.0210, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 89 | [Avg. Reward]: 29.662200927734375 | [Avg. Cost]: 0.12099999934434891 | [Elapsed Time]: 6:44:04\n",
      "tensor(-0.0286, device='cuda:0') tensor(-0.0234, device='cuda:0')\n",
      "tensor(-0.0232, device='cuda:0') tensor(-0.0234, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 90 | [Avg. Reward]: 29.843360900878906 | [Avg. Cost]: 0.12343999743461609 | [Elapsed Time]: 6:48:02\n",
      "tensor(-0.0312, device='cuda:0') tensor(-0.0206, device='cuda:0')\n",
      "tensor(-0.0253, device='cuda:0') tensor(-0.0206, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 91 | [Avg. Reward]: 29.729360580444336 | [Avg. Cost]: 0.12064000219106674 | [Elapsed Time]: 6:52:00\n",
      "tensor(-0.0290, device='cuda:0') tensor(-0.0235, device='cuda:0')\n",
      "tensor(-0.0235, device='cuda:0') tensor(-0.0235, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 92 | [Avg. Reward]: 29.72011947631836 | [Avg. Cost]: 0.12347999960184097 | [Elapsed Time]: 6:56:01\n",
      "tensor(-0.0229, device='cuda:0') tensor(-0.0195, device='cuda:0')\n",
      "tensor(-0.0186, device='cuda:0') tensor(-0.0195, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 93 | [Avg. Reward]: 29.680879592895508 | [Avg. Cost]: 0.11952000111341476 | [Elapsed Time]: 6:59:59\n",
      "tensor(-0.0182, device='cuda:0') tensor(-0.0202, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 94 | [Avg. Reward]: 29.932199478149414 | [Avg. Cost]: 0.12020000070333481 | [Elapsed Time]: 7:08:41\n",
      "tensor(-0.0201, device='cuda:0') tensor(-0.0198, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 95 | [Avg. Reward]: 29.83216094970703 | [Avg. Cost]: 0.11984000355005264 | [Elapsed Time]: 7:12:33\n",
      "tensor(-0.0262, device='cuda:0') tensor(-0.0202, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 96 | [Avg. Reward]: 29.813440322875977 | [Avg. Cost]: 0.12015999853610992 | [Elapsed Time]: 7:16:31\n",
      "tensor(-0.0222, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 97 | [Avg. Reward]: 30.092880249023438 | [Avg. Cost]: 0.11912000179290771 | [Elapsed Time]: 7:20:28\n",
      "tensor(-0.0217, device='cuda:0') tensor(-0.0190, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 98 | [Avg. Reward]: 29.86743927001953 | [Avg. Cost]: 0.11896000057458878 | [Elapsed Time]: 7:24:26\n",
      "tensor(-0.0307, device='cuda:0') tensor(-0.0209, device='cuda:0')\n",
      "tensor(-0.0249, device='cuda:0') tensor(-0.0209, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 99 | [Avg. Reward]: 30.05668067932129 | [Avg. Cost]: 0.12092000246047974 | [Elapsed Time]: 7:28:23\n",
      "tensor(-0.0127, device='cuda:0') tensor(-0.0170, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 100 | [Avg. Reward]: 30.010160446166992 | [Avg. Cost]: 0.1170400008559227 | [Elapsed Time]: 7:32:23\n",
      "tensor(-0.0305, device='cuda:0') tensor(-0.0222, device='cuda:0')\n",
      "tensor(-0.0247, device='cuda:0') tensor(-0.0222, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 101 | [Avg. Reward]: 30.290159225463867 | [Avg. Cost]: 0.12223999947309494 | [Elapsed Time]: 7:36:21\n",
      "tensor(-0.0240, device='cuda:0') tensor(-0.0211, device='cuda:0')\n",
      "tensor(-0.0194, device='cuda:0') tensor(-0.0211, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 102 | [Avg. Reward]: 30.248519897460938 | [Avg. Cost]: 0.12108000367879868 | [Elapsed Time]: 7:40:19\n",
      "tensor(-0.0237, device='cuda:0') tensor(-0.0188, device='cuda:0')\n",
      "tensor(-0.0192, device='cuda:0') tensor(-0.0188, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 103 | [Avg. Reward]: 30.006759643554688 | [Avg. Cost]: 0.11884000152349472 | [Elapsed Time]: 7:48:41\n",
      "tensor(-0.0216, device='cuda:0') tensor(-0.0200, device='cuda:0')\n",
      "tensor(-0.0175, device='cuda:0') tensor(-0.0200, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 104 | [Avg. Reward]: 30.2951602935791 | [Avg. Cost]: 0.12003999948501587 | [Elapsed Time]: 7:52:33\n",
      "tensor(-0.0212, device='cuda:0') tensor(-0.0201, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 105 | [Avg. Reward]: 30.226280212402344 | [Avg. Cost]: 0.12011999636888504 | [Elapsed Time]: 7:56:27\n",
      "tensor(-0.0163, device='cuda:0') tensor(-0.0166, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 106 | [Avg. Reward]: 30.24180030822754 | [Avg. Cost]: 0.11659999936819077 | [Elapsed Time]: 8:00:23\n",
      "tensor(-0.0158, device='cuda:0') tensor(-0.0205, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 107 | [Avg. Reward]: 30.205080032348633 | [Avg. Cost]: 0.12052000313997269 | [Elapsed Time]: 8:04:19\n",
      "tensor(-0.0191, device='cuda:0') tensor(-0.0169, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 108 | [Avg. Reward]: 30.27911949157715 | [Avg. Cost]: 0.11687999963760376 | [Elapsed Time]: 8:08:15\n",
      "tensor(-0.0283, device='cuda:0') tensor(-0.0231, device='cuda:0')\n",
      "tensor(-0.0229, device='cuda:0') tensor(-0.0231, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode]: 109 | [Avg. Reward]: 30.30971908569336 | [Avg. Cost]: 0.12308000028133392 | [Elapsed Time]: 8:12:11\n",
      "tensor(-0.0288, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 110 | [Avg. Reward]: 30.30847930908203 | [Avg. Cost]: 0.11912000179290771 | [Elapsed Time]: 8:16:08\n",
      "tensor(-0.0108, device='cuda:0') tensor(-0.0170, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 111 | [Avg. Reward]: 30.202640533447266 | [Avg. Cost]: 0.11695999652147293 | [Elapsed Time]: 8:24:40\n",
      "tensor(-0.0170, device='cuda:0') tensor(-0.0180, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 112 | [Avg. Reward]: 30.530399322509766 | [Avg. Cost]: 0.11800000071525574 | [Elapsed Time]: 8:28:36\n",
      "tensor(-0.0156, device='cuda:0') tensor(-0.0162, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 113 | [Avg. Reward]: 30.519399642944336 | [Avg. Cost]: 0.11620000004768372 | [Elapsed Time]: 8:32:32\n",
      "tensor(-0.0199, device='cuda:0') tensor(-0.0222, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 114 | [Avg. Reward]: 30.672239303588867 | [Avg. Cost]: 0.12216000258922577 | [Elapsed Time]: 8:36:28\n",
      "tensor(-0.0280, device='cuda:0') tensor(-0.0258, device='cuda:0')\n",
      "tensor(-0.0227, device='cuda:0') tensor(-0.0258, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 115 | [Avg. Reward]: 30.731840133666992 | [Avg. Cost]: 0.1257600039243698 | [Elapsed Time]: 8:40:25\n",
      "tensor(-0.0211, device='cuda:0') tensor(-0.0202, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 116 | [Avg. Reward]: 30.748239517211914 | [Avg. Cost]: 0.12015999853610992 | [Elapsed Time]: 8:44:21\n",
      "tensor(-0.0285, device='cuda:0') tensor(-0.0250, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 117 | [Avg. Reward]: 30.898160934448242 | [Avg. Cost]: 0.1250399947166443 | [Elapsed Time]: 8:48:17\n",
      "tensor(-0.0334, device='cuda:0') tensor(-0.0228, device='cuda:0')\n",
      "tensor(-0.0271, device='cuda:0') tensor(-0.0228, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 118 | [Avg. Reward]: 30.79475975036621 | [Avg. Cost]: 0.12284000217914581 | [Elapsed Time]: 8:52:15\n",
      "tensor(-0.0127, device='cuda:0') tensor(-0.0172, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 119 | [Avg. Reward]: 30.733200073242188 | [Avg. Cost]: 0.11720000207424164 | [Elapsed Time]: 9:00:53\n",
      "tensor(-0.0243, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "tensor(-0.0197, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 120 | [Avg. Reward]: 30.721200942993164 | [Avg. Cost]: 0.12200000137090683 | [Elapsed Time]: 9:04:48\n",
      "tensor(-0.0318, device='cuda:0') tensor(-0.0256, device='cuda:0')\n",
      "tensor(-0.0258, device='cuda:0') tensor(-0.0256, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 121 | [Avg. Reward]: 30.742000579833984 | [Avg. Cost]: 0.12559999525547028 | [Elapsed Time]: 9:08:45\n",
      "tensor(-0.0272, device='cuda:0') tensor(-0.0252, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 122 | [Avg. Reward]: 30.95800018310547 | [Avg. Cost]: 0.12520000338554382 | [Elapsed Time]: 9:12:41\n",
      "tensor(-0.0222, device='cuda:0') tensor(-0.0188, device='cuda:0')\n",
      "tensor(-0.0180, device='cuda:0') tensor(-0.0188, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 123 | [Avg. Reward]: 30.822839736938477 | [Avg. Cost]: 0.11875999718904495 | [Elapsed Time]: 9:16:38\n",
      "tensor(-0.0222, device='cuda:0') tensor(-0.0229, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 124 | [Avg. Reward]: 31.008319854736328 | [Avg. Cost]: 0.1228799968957901 | [Elapsed Time]: 9:20:37\n",
      "tensor(-0.0209, device='cuda:0') tensor(-0.0232, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 125 | [Avg. Reward]: 30.95516014099121 | [Avg. Cost]: 0.12324000149965286 | [Elapsed Time]: 9:24:34\n",
      "tensor(-0.0171, device='cuda:0') tensor(-0.0210, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 126 | [Avg. Reward]: 30.9410400390625 | [Avg. Cost]: 0.12095999717712402 | [Elapsed Time]: 9:28:33\n",
      "tensor(-0.0246, device='cuda:0') tensor(-0.0196, device='cuda:0')\n",
      "tensor(-0.0199, device='cuda:0') tensor(-0.0196, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 127 | [Avg. Reward]: 31.071239471435547 | [Avg. Cost]: 0.11956000328063965 | [Elapsed Time]: 9:32:30\n",
      "tensor(-0.0226, device='cuda:0') tensor(-0.0264, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 128 | [Avg. Reward]: 31.032440185546875 | [Avg. Cost]: 0.1263599991798401 | [Elapsed Time]: 9:41:11\n",
      "tensor(-0.0144, device='cuda:0') tensor(-0.0169, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 129 | [Avg. Reward]: 31.054279327392578 | [Avg. Cost]: 0.11692000180482864 | [Elapsed Time]: 9:45:02\n",
      "tensor(-0.0204, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 130 | [Avg. Reward]: 31.07699966430664 | [Avg. Cost]: 0.12139999866485596 | [Elapsed Time]: 9:48:59\n",
      "tensor(-0.0302, device='cuda:0') tensor(-0.0221, device='cuda:0')\n",
      "tensor(-0.0244, device='cuda:0') tensor(-0.0221, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 131 | [Avg. Reward]: 30.886720657348633 | [Avg. Cost]: 0.122079998254776 | [Elapsed Time]: 9:52:54\n",
      "tensor(-0.0204, device='cuda:0') tensor(-0.0179, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 132 | [Avg. Reward]: 31.250120162963867 | [Avg. Cost]: 0.11788000166416168 | [Elapsed Time]: 9:56:50\n",
      "tensor(-0.0215, device='cuda:0') tensor(-0.0206, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 133 | [Avg. Reward]: 31.207040786743164 | [Avg. Cost]: 0.12055999785661697 | [Elapsed Time]: 10:00:46\n",
      "tensor(-0.0163, device='cuda:0') tensor(-0.0168, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 134 | [Avg. Reward]: 31.24519920349121 | [Avg. Cost]: 0.11680000275373459 | [Elapsed Time]: 10:04:42\n",
      "tensor(-0.0241, device='cuda:0') tensor(-0.0235, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 135 | [Avg. Reward]: 31.326080322265625 | [Avg. Cost]: 0.12352000176906586 | [Elapsed Time]: 10:08:39\n",
      "tensor(-0.0201, device='cuda:0') tensor(-0.0193, device='cuda:0')\n",
      "tensor(-0.0162, device='cuda:0') tensor(-0.0193, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 136 | [Avg. Reward]: 31.179920196533203 | [Avg. Cost]: 0.11928000301122665 | [Elapsed Time]: 10:17:13\n",
      "tensor(-0.0227, device='cuda:0') tensor(-0.0197, device='cuda:0')\n",
      "tensor(-0.0184, device='cuda:0') tensor(-0.0197, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 137 | [Avg. Reward]: 31.36832046508789 | [Avg. Cost]: 0.1196800023317337 | [Elapsed Time]: 10:21:07\n",
      "tensor(-0.0189, device='cuda:0') tensor(-0.0165, device='cuda:0')\n",
      "tensor(-0.0153, device='cuda:0') tensor(-0.0165, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 138 | [Avg. Reward]: 31.266679763793945 | [Avg. Cost]: 0.1165200024843216 | [Elapsed Time]: 10:25:05\n",
      "tensor(-0.0227, device='cuda:0') tensor(-0.0219, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 139 | [Avg. Reward]: 31.3585205078125 | [Avg. Cost]: 0.12188000231981277 | [Elapsed Time]: 10:29:01\n",
      "tensor(-0.0159, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 140 | [Avg. Reward]: 31.456439971923828 | [Avg. Cost]: 0.12116000056266785 | [Elapsed Time]: 10:32:58\n",
      "tensor(-0.0221, device='cuda:0') tensor(-0.0196, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 141 | [Avg. Reward]: 31.4952392578125 | [Avg. Cost]: 0.11956000328063965 | [Elapsed Time]: 10:36:55\n",
      "tensor(-0.0197, device='cuda:0') tensor(-0.0202, device='cuda:0')\n",
      "tensor(-0.0159, device='cuda:0') tensor(-0.0202, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 142 | [Avg. Reward]: 31.429840087890625 | [Avg. Cost]: 0.12015999853610992 | [Elapsed Time]: 10:40:53\n",
      "tensor(-0.0243, device='cuda:0') tensor(-0.0213, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 143 | [Avg. Reward]: 31.522279739379883 | [Avg. Cost]: 0.12132000178098679 | [Elapsed Time]: 10:44:51\n",
      "tensor(-0.0206, device='cuda:0') tensor(-0.0180, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 144 | [Avg. Reward]: 31.598840713500977 | [Avg. Cost]: 0.11795999854803085 | [Elapsed Time]: 10:53:07\n",
      "tensor(-0.0193, device='cuda:0') tensor(-0.0226, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 145 | [Avg. Reward]: 31.60856056213379 | [Avg. Cost]: 0.12263999879360199 | [Elapsed Time]: 10:57:18\n",
      "tensor(-0.0222, device='cuda:0') tensor(-0.0244, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 146 | [Avg. Reward]: 31.666400909423828 | [Avg. Cost]: 0.12439999729394913 | [Elapsed Time]: 11:01:08\n",
      "tensor(-0.0180, device='cuda:0') tensor(-0.0179, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 147 | [Avg. Reward]: 31.646879196166992 | [Avg. Cost]: 0.11791999638080597 | [Elapsed Time]: 11:05:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0311, device='cuda:0') tensor(-0.0259, device='cuda:0')\n",
      "tensor(-0.0252, device='cuda:0') tensor(-0.0259, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 148 | [Avg. Reward]: 31.67367935180664 | [Avg. Cost]: 0.12591999769210815 | [Elapsed Time]: 11:08:57\n",
      "tensor(-0.0190, device='cuda:0') tensor(-0.0204, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 149 | [Avg. Reward]: 31.765960693359375 | [Avg. Cost]: 0.12043999880552292 | [Elapsed Time]: 11:12:52\n",
      "tensor(-0.0189, device='cuda:0') tensor(-0.0219, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 150 | [Avg. Reward]: 31.731679916381836 | [Avg. Cost]: 0.12191999703645706 | [Elapsed Time]: 11:16:47\n",
      "tensor(-0.0236, device='cuda:0') tensor(-0.0244, device='cuda:0')\n",
      "tensor(-0.0191, device='cuda:0') tensor(-0.0244, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 151 | [Avg. Reward]: 31.74675941467285 | [Avg. Cost]: 0.12443999946117401 | [Elapsed Time]: 11:20:44\n",
      "tensor(-0.0193, device='cuda:0') tensor(-0.0206, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 152 | [Avg. Reward]: 31.62735939025879 | [Avg. Cost]: 0.12064000219106674 | [Elapsed Time]: 11:24:40\n",
      "tensor(-0.0184, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "tensor(-0.0149, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 153 | [Avg. Reward]: 31.84943962097168 | [Avg. Cost]: 0.12135999649763107 | [Elapsed Time]: 11:33:08\n",
      "tensor(-0.0128, device='cuda:0') tensor(-0.0188, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 154 | [Avg. Reward]: 31.881559371948242 | [Avg. Cost]: 0.11884000152349472 | [Elapsed Time]: 11:36:58\n",
      "tensor(-0.0295, device='cuda:0') tensor(-0.0238, device='cuda:0')\n",
      "tensor(-0.0239, device='cuda:0') tensor(-0.0238, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 155 | [Avg. Reward]: 32.045799255371094 | [Avg. Cost]: 0.12380000203847885 | [Elapsed Time]: 11:40:52\n",
      "tensor(-0.0214, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "tensor(-0.0173, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 156 | [Avg. Reward]: 31.846439361572266 | [Avg. Cost]: 0.12116000056266785 | [Elapsed Time]: 11:44:46\n",
      "tensor(-0.0312, device='cuda:0') tensor(-0.0257, device='cuda:0')\n",
      "tensor(-0.0253, device='cuda:0') tensor(-0.0257, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 157 | [Avg. Reward]: 31.82592010498047 | [Avg. Cost]: 0.12567999958992004 | [Elapsed Time]: 11:48:40\n",
      "tensor(-0.0248, device='cuda:0') tensor(-0.0200, device='cuda:0')\n",
      "tensor(-0.0201, device='cuda:0') tensor(-0.0200, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 158 | [Avg. Reward]: 31.99519920349121 | [Avg. Cost]: 0.11999999731779099 | [Elapsed Time]: 11:52:35\n",
      "tensor(-0.0266, device='cuda:0') tensor(-0.0232, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 159 | [Avg. Reward]: 31.874040603637695 | [Avg. Cost]: 0.1231599971652031 | [Elapsed Time]: 11:56:30\n",
      "tensor(-0.0217, device='cuda:0') tensor(-0.0195, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 160 | [Avg. Reward]: 31.983320236206055 | [Avg. Cost]: 0.11947999894618988 | [Elapsed Time]: 12:00:26\n",
      "tensor(-0.0130, device='cuda:0') tensor(-0.0166, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 161 | [Avg. Reward]: 32.0605583190918 | [Avg. Cost]: 0.11664000153541565 | [Elapsed Time]: 12:09:07\n",
      "tensor(-0.0207, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 162 | [Avg. Reward]: 31.990800857543945 | [Avg. Cost]: 0.12200000137090683 | [Elapsed Time]: 12:12:57\n",
      "tensor(-0.0244, device='cuda:0') tensor(-0.0249, device='cuda:0')\n",
      "tensor(-0.0198, device='cuda:0') tensor(-0.0249, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 163 | [Avg. Reward]: 32.146278381347656 | [Avg. Cost]: 0.12492000311613083 | [Elapsed Time]: 12:16:53\n",
      "tensor(-0.0205, device='cuda:0') tensor(-0.0203, device='cuda:0')\n",
      "tensor(-0.0166, device='cuda:0') tensor(-0.0203, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 164 | [Avg. Reward]: 32.1361198425293 | [Avg. Cost]: 0.12027999758720398 | [Elapsed Time]: 12:20:48\n",
      "tensor(-0.0204, device='cuda:0') tensor(-0.0189, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 165 | [Avg. Reward]: 32.18471908569336 | [Avg. Cost]: 0.1188800036907196 | [Elapsed Time]: 12:24:42\n",
      "tensor(-0.0194, device='cuda:0') tensor(-0.0169, device='cuda:0')\n",
      "tensor(-0.0157, device='cuda:0') tensor(-0.0169, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 166 | [Avg. Reward]: 32.194679260253906 | [Avg. Cost]: 0.11692000180482864 | [Elapsed Time]: 12:28:39\n",
      "tensor(-0.0213, device='cuda:0') tensor(-0.0215, device='cuda:0')\n",
      "tensor(-0.0173, device='cuda:0') tensor(-0.0215, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 167 | [Avg. Reward]: 32.15208053588867 | [Avg. Cost]: 0.12151999771595001 | [Elapsed Time]: 12:32:34\n",
      "tensor(-0.0286, device='cuda:0') tensor(-0.0223, device='cuda:0')\n",
      "tensor(-0.0232, device='cuda:0') tensor(-0.0223, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 168 | [Avg. Reward]: 32.29331970214844 | [Avg. Cost]: 0.12228000164031982 | [Elapsed Time]: 12:36:31\n",
      "tensor(-0.0246, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "tensor(-0.0199, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 169 | [Avg. Reward]: 32.184959411621094 | [Avg. Cost]: 0.12144000083208084 | [Elapsed Time]: 12:44:56\n",
      "tensor(-0.0144, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 170 | [Avg. Reward]: 32.24208068847656 | [Avg. Cost]: 0.11912000179290771 | [Elapsed Time]: 12:49:00\n",
      "tensor(-0.0220, device='cuda:0') tensor(-0.0233, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 171 | [Avg. Reward]: 32.345481872558594 | [Avg. Cost]: 0.12331999838352203 | [Elapsed Time]: 12:52:52\n",
      "tensor(-0.0163, device='cuda:0') tensor(-0.0228, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 172 | [Avg. Reward]: 32.40044021606445 | [Avg. Cost]: 0.12275999784469604 | [Elapsed Time]: 12:56:59\n",
      "tensor(-0.0210, device='cuda:0') tensor(-0.0232, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 173 | [Avg. Reward]: 32.43159866333008 | [Avg. Cost]: 0.12319999933242798 | [Elapsed Time]: 13:01:07\n",
      "tensor(-0.0317, device='cuda:0') tensor(-0.0238, device='cuda:0')\n",
      "tensor(-0.0257, device='cuda:0') tensor(-0.0238, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 174 | [Avg. Reward]: 32.4921989440918 | [Avg. Cost]: 0.12380000203847885 | [Elapsed Time]: 13:05:13\n",
      "tensor(-0.0174, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "tensor(-0.0141, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 175 | [Avg. Reward]: 32.42287826538086 | [Avg. Cost]: 0.11912000179290771 | [Elapsed Time]: 13:09:21\n",
      "tensor(-0.0216, device='cuda:0') tensor(-0.0253, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 176 | [Avg. Reward]: 32.4647216796875 | [Avg. Cost]: 0.1252799928188324 | [Elapsed Time]: 13:13:29\n",
      "tensor(-0.0213, device='cuda:0') tensor(-0.0238, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 177 | [Avg. Reward]: 32.41223907470703 | [Avg. Cost]: 0.12375999987125397 | [Elapsed Time]: 13:17:40\n",
      "tensor(-0.0294, device='cuda:0') tensor(-0.0263, device='cuda:0')\n",
      "tensor(-0.0238, device='cuda:0') tensor(-0.0263, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 178 | [Avg. Reward]: 32.600120544433594 | [Avg. Cost]: 0.12627999484539032 | [Elapsed Time]: 13:26:29\n",
      "tensor(-0.0253, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "tensor(-0.0205, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 179 | [Avg. Reward]: 32.61555862426758 | [Avg. Cost]: 0.12204000353813171 | [Elapsed Time]: 13:30:35\n",
      "tensor(-0.0219, device='cuda:0') tensor(-0.0174, device='cuda:0')\n",
      "tensor(-0.0177, device='cuda:0') tensor(-0.0174, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 180 | [Avg. Reward]: 32.51496124267578 | [Avg. Cost]: 0.11744000017642975 | [Elapsed Time]: 13:34:44\n",
      "tensor(-0.0235, device='cuda:0') tensor(-0.0189, device='cuda:0')\n",
      "tensor(-0.0191, device='cuda:0') tensor(-0.0189, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 181 | [Avg. Reward]: 32.68027877807617 | [Avg. Cost]: 0.11891999840736389 | [Elapsed Time]: 13:38:52\n",
      "tensor(-0.0183, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 182 | [Avg. Reward]: 32.5352783203125 | [Avg. Cost]: 0.11912000179290771 | [Elapsed Time]: 13:43:00\n",
      "tensor(-0.0155, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "tensor(-0.0125, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode]: 183 | [Avg. Reward]: 32.60655975341797 | [Avg. Cost]: 0.12184000015258789 | [Elapsed Time]: 13:47:11\n",
      "tensor(-0.0185, device='cuda:0') tensor(-0.0201, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 184 | [Avg. Reward]: 32.743919372558594 | [Avg. Cost]: 0.12008000165224075 | [Elapsed Time]: 13:51:13\n",
      "tensor(-0.0212, device='cuda:0') tensor(-0.0244, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 185 | [Avg. Reward]: 32.713958740234375 | [Avg. Cost]: 0.12443999946117401 | [Elapsed Time]: 13:55:11\n",
      "tensor(-0.0238, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "tensor(-0.0193, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 186 | [Avg. Reward]: 32.760040283203125 | [Avg. Cost]: 0.12116000056266785 | [Elapsed Time]: 14:03:47\n",
      "tensor(-0.0181, device='cuda:0') tensor(-0.0207, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 187 | [Avg. Reward]: 32.83287811279297 | [Avg. Cost]: 0.12071999907493591 | [Elapsed Time]: 14:07:40\n",
      "tensor(-0.0221, device='cuda:0') tensor(-0.0250, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 188 | [Avg. Reward]: 32.752559661865234 | [Avg. Cost]: 0.1250399947166443 | [Elapsed Time]: 14:11:36\n",
      "tensor(-0.0179, device='cuda:0') tensor(-0.0205, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 189 | [Avg. Reward]: 32.57992172241211 | [Avg. Cost]: 0.1204800009727478 | [Elapsed Time]: 14:15:33\n",
      "tensor(-0.0271, device='cuda:0') tensor(-0.0279, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 190 | [Avg. Reward]: 32.92412185668945 | [Avg. Cost]: 0.1278800070285797 | [Elapsed Time]: 14:19:30\n",
      "tensor(-0.0257, device='cuda:0') tensor(-0.0189, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 191 | [Avg. Reward]: 32.88671875 | [Avg. Cost]: 0.1188800036907196 | [Elapsed Time]: 14:23:26\n",
      "tensor(-0.0229, device='cuda:0') tensor(-0.0213, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 192 | [Avg. Reward]: 32.903480529785156 | [Avg. Cost]: 0.12132000178098679 | [Elapsed Time]: 14:27:23\n",
      "tensor(-0.0189, device='cuda:0') tensor(-0.0236, device='cuda:0')\n",
      "tensor(-0.0153, device='cuda:0') tensor(-0.0236, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 193 | [Avg. Reward]: 32.77315902709961 | [Avg. Cost]: 0.12364000082015991 | [Elapsed Time]: 14:31:21\n",
      "tensor(-0.0206, device='cuda:0') tensor(-0.0195, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 194 | [Avg. Reward]: 32.9581184387207 | [Avg. Cost]: 0.11947999894618988 | [Elapsed Time]: 14:35:19\n",
      "tensor(-0.0253, device='cuda:0') tensor(-0.0209, device='cuda:0')\n",
      "tensor(-0.0205, device='cuda:0') tensor(-0.0209, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 195 | [Avg. Reward]: 32.80268096923828 | [Avg. Cost]: 0.12092000246047974 | [Elapsed Time]: 14:43:48\n",
      "tensor(-0.0202, device='cuda:0') tensor(-0.0217, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 196 | [Avg. Reward]: 33.11511993408203 | [Avg. Cost]: 0.12167999893426895 | [Elapsed Time]: 14:47:41\n",
      "tensor(-0.0295, device='cuda:0') tensor(-0.0198, device='cuda:0')\n",
      "tensor(-0.0239, device='cuda:0') tensor(-0.0198, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 197 | [Avg. Reward]: 32.96855926513672 | [Avg. Cost]: 0.11984000355005264 | [Elapsed Time]: 14:51:38\n",
      "tensor(-0.0164, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 198 | [Avg. Reward]: 32.93212127685547 | [Avg. Cost]: 0.11907999962568283 | [Elapsed Time]: 14:55:35\n",
      "tensor(-0.0190, device='cuda:0') tensor(-0.0162, device='cuda:0')\n",
      "tensor(-0.0154, device='cuda:0') tensor(-0.0162, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 199 | [Avg. Reward]: 32.863040924072266 | [Avg. Cost]: 0.11615999788045883 | [Elapsed Time]: 14:59:33\n",
      "tensor(-0.0197, device='cuda:0') tensor(-0.0177, device='cuda:0')\n",
      "tensor(-0.0159, device='cuda:0') tensor(-0.0177, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 200 | [Avg. Reward]: 32.899478912353516 | [Avg. Cost]: 0.11772000044584274 | [Elapsed Time]: 15:03:30\n",
      "tensor(-0.0186, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "tensor(-0.0151, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 201 | [Avg. Reward]: 33.15956115722656 | [Avg. Cost]: 0.12204000353813171 | [Elapsed Time]: 15:07:26\n",
      "tensor(-0.0177, device='cuda:0') tensor(-0.0194, device='cuda:0')\n",
      "tensor(-0.0144, device='cuda:0') tensor(-0.0194, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 202 | [Avg. Reward]: 33.01704025268555 | [Avg. Cost]: 0.11935999989509583 | [Elapsed Time]: 15:11:24\n",
      "tensor(-0.0212, device='cuda:0') tensor(-0.0246, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 203 | [Avg. Reward]: 33.044559478759766 | [Avg. Cost]: 0.12464000284671783 | [Elapsed Time]: 15:19:58\n",
      "tensor(-0.0263, device='cuda:0') tensor(-0.0261, device='cuda:0')\n",
      "tensor(-0.0213, device='cuda:0') tensor(-0.0261, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 204 | [Avg. Reward]: 33.291080474853516 | [Avg. Cost]: 0.12612000107765198 | [Elapsed Time]: 15:23:52\n",
      "tensor(-0.0132, device='cuda:0') tensor(-0.0156, device='cuda:0')\n",
      "tensor(-0.0107, device='cuda:0') tensor(-0.0156, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 205 | [Avg. Reward]: 33.26599884033203 | [Avg. Cost]: 0.11559999734163284 | [Elapsed Time]: 15:27:49\n",
      "tensor(-0.0174, device='cuda:0') tensor(-0.0230, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 206 | [Avg. Reward]: 33.43259811401367 | [Avg. Cost]: 0.12300000339746475 | [Elapsed Time]: 15:31:45\n",
      "tensor(-0.0215, device='cuda:0') tensor(-0.0226, device='cuda:0')\n",
      "tensor(-0.0174, device='cuda:0') tensor(-0.0226, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 207 | [Avg. Reward]: 33.50664138793945 | [Avg. Cost]: 0.12256000190973282 | [Elapsed Time]: 15:35:41\n",
      "tensor(-0.0323, device='cuda:0') tensor(-0.0266, device='cuda:0')\n",
      "tensor(-0.0261, device='cuda:0') tensor(-0.0266, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 208 | [Avg. Reward]: 33.62139892578125 | [Avg. Cost]: 0.1265999972820282 | [Elapsed Time]: 15:39:36\n",
      "tensor(-0.0240, device='cuda:0') tensor(-0.0239, device='cuda:0')\n",
      "tensor(-0.0194, device='cuda:0') tensor(-0.0239, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 209 | [Avg. Reward]: 33.51887893676758 | [Avg. Cost]: 0.1239200010895729 | [Elapsed Time]: 15:43:33\n",
      "tensor(-0.0203, device='cuda:0') tensor(-0.0234, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 210 | [Avg. Reward]: 33.634159088134766 | [Avg. Cost]: 0.12343999743461609 | [Elapsed Time]: 15:47:28\n",
      "tensor(-0.0226, device='cuda:0') tensor(-0.0248, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 211 | [Avg. Reward]: 33.6043586730957 | [Avg. Cost]: 0.12483999878168106 | [Elapsed Time]: 15:56:06\n",
      "tensor(-0.0333, device='cuda:0') tensor(-0.0291, device='cuda:0')\n",
      "tensor(-0.0270, device='cuda:0') tensor(-0.0291, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 212 | [Avg. Reward]: 33.54011917114258 | [Avg. Cost]: 0.12907999753952026 | [Elapsed Time]: 15:59:59\n",
      "tensor(-0.0269, device='cuda:0') tensor(-0.0264, device='cuda:0')\n",
      "tensor(-0.0217, device='cuda:0') tensor(-0.0264, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 213 | [Avg. Reward]: 33.54404067993164 | [Avg. Cost]: 0.1263599991798401 | [Elapsed Time]: 16:03:56\n",
      "tensor(-0.0239, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "tensor(-0.0193, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 214 | [Avg. Reward]: 33.61056137084961 | [Avg. Cost]: 0.12184000015258789 | [Elapsed Time]: 16:07:53\n",
      "tensor(-0.0229, device='cuda:0') tensor(-0.0247, device='cuda:0')\n",
      "tensor(-0.0185, device='cuda:0') tensor(-0.0247, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 215 | [Avg. Reward]: 33.56052017211914 | [Avg. Cost]: 0.12467999756336212 | [Elapsed Time]: 16:11:50\n",
      "tensor(-0.0228, device='cuda:0') tensor(-0.0265, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 216 | [Avg. Reward]: 33.55992126464844 | [Avg. Cost]: 0.12647999823093414 | [Elapsed Time]: 16:15:47\n",
      "tensor(-0.0167, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "tensor(-0.0135, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 217 | [Avg. Reward]: 33.53976058959961 | [Avg. Cost]: 0.12144000083208084 | [Elapsed Time]: 16:19:44\n",
      "tensor(-0.0223, device='cuda:0') tensor(-0.0247, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 218 | [Avg. Reward]: 33.577720642089844 | [Avg. Cost]: 0.12467999756336212 | [Elapsed Time]: 16:23:40\n",
      "tensor(-0.0237, device='cuda:0') tensor(-0.0254, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode]: 219 | [Avg. Reward]: 33.48503875732422 | [Avg. Cost]: 0.12535999715328217 | [Elapsed Time]: 16:27:36\n",
      "tensor(-0.0200, device='cuda:0') tensor(-0.0184, device='cuda:0')\n",
      "tensor(-0.0162, device='cuda:0') tensor(-0.0184, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 220 | [Avg. Reward]: 33.628761291503906 | [Avg. Cost]: 0.11844000220298767 | [Elapsed Time]: 16:36:00\n",
      "tensor(-0.0217, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 221 | [Avg. Reward]: 33.56455993652344 | [Avg. Cost]: 0.12184000015258789 | [Elapsed Time]: 16:39:51\n",
      "tensor(-0.0287, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "tensor(-0.0233, device='cuda:0') tensor(-0.0214, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 222 | [Avg. Reward]: 33.70296096801758 | [Avg. Cost]: 0.12144000083208084 | [Elapsed Time]: 16:43:45\n",
      "tensor(-0.0153, device='cuda:0') tensor(-0.0191, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 223 | [Avg. Reward]: 33.567718505859375 | [Avg. Cost]: 0.11907999962568283 | [Elapsed Time]: 16:47:39\n",
      "tensor(-0.0190, device='cuda:0') tensor(-0.0205, device='cuda:0')\n",
      "tensor(-0.0154, device='cuda:0') tensor(-0.0205, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 224 | [Avg. Reward]: 33.66427993774414 | [Avg. Cost]: 0.12052000313997269 | [Elapsed Time]: 16:51:35\n",
      "tensor(-0.0203, device='cuda:0') tensor(-0.0222, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 225 | [Avg. Reward]: 33.704158782958984 | [Avg. Cost]: 0.12223999947309494 | [Elapsed Time]: 16:55:30\n",
      "tensor(-0.0190, device='cuda:0') tensor(-0.0193, device='cuda:0')\n",
      "tensor(-0.0154, device='cuda:0') tensor(-0.0193, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 226 | [Avg. Reward]: 33.84431838989258 | [Avg. Cost]: 0.11928000301122665 | [Elapsed Time]: 16:59:25\n",
      "tensor(-0.0275, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "tensor(-0.0223, device='cuda:0') tensor(-0.0218, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 227 | [Avg. Reward]: 33.9770393371582 | [Avg. Cost]: 0.12176000326871872 | [Elapsed Time]: 17:03:22\n",
      "tensor(-0.0215, device='cuda:0') tensor(-0.0256, device='cuda:0')\n",
      "tensor(-0.0174, device='cuda:0') tensor(-0.0256, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 228 | [Avg. Reward]: 33.90604019165039 | [Avg. Cost]: 0.125560000538826 | [Elapsed Time]: 17:12:03\n",
      "tensor(-0.0283, device='cuda:0') tensor(-0.0263, device='cuda:0')\n",
      "tensor(-0.0229, device='cuda:0') tensor(-0.0263, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 229 | [Avg. Reward]: 33.72611999511719 | [Avg. Cost]: 0.12627999484539032 | [Elapsed Time]: 17:16:10\n",
      "tensor(-0.0211, device='cuda:0') tensor(-0.0238, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 230 | [Avg. Reward]: 33.77975845336914 | [Avg. Cost]: 0.12383999675512314 | [Elapsed Time]: 17:20:20\n",
      "tensor(-0.0184, device='cuda:0') tensor(-0.0184, device='cuda:0')\n",
      "tensor(-0.0149, device='cuda:0') tensor(-0.0184, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 231 | [Avg. Reward]: 33.63164138793945 | [Avg. Cost]: 0.1183599978685379 | [Elapsed Time]: 17:24:31\n",
      "tensor(-0.0209, device='cuda:0') tensor(-0.0228, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 232 | [Avg. Reward]: 33.764801025390625 | [Avg. Cost]: 0.12280000001192093 | [Elapsed Time]: 17:28:35\n",
      "tensor(-0.0171, device='cuda:0') tensor(-0.0203, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 233 | [Avg. Reward]: 33.69927978515625 | [Avg. Cost]: 0.12031999975442886 | [Elapsed Time]: 17:32:32\n",
      "tensor(-0.0202, device='cuda:0') tensor(-0.0194, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 234 | [Avg. Reward]: 34.05464172363281 | [Avg. Cost]: 0.11935999989509583 | [Elapsed Time]: 17:36:27\n",
      "tensor(-0.0182, device='cuda:0') tensor(-0.0208, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 235 | [Avg. Reward]: 33.947200775146484 | [Avg. Cost]: 0.12080000340938568 | [Elapsed Time]: 17:40:23\n",
      "tensor(-0.0195, device='cuda:0') tensor(-0.0231, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 236 | [Avg. Reward]: 33.89371871948242 | [Avg. Cost]: 0.12308000028133392 | [Elapsed Time]: 17:49:01\n",
      "tensor(-0.0225, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 237 | [Avg. Reward]: 33.92876052856445 | [Avg. Cost]: 0.12123999744653702 | [Elapsed Time]: 17:52:55\n",
      "tensor(-0.0157, device='cuda:0') tensor(-0.0192, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 238 | [Avg. Reward]: 33.943241119384766 | [Avg. Cost]: 0.119159996509552 | [Elapsed Time]: 17:56:50\n",
      "tensor(-0.0232, device='cuda:0') tensor(-0.0220, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 239 | [Avg. Reward]: 34.13119888305664 | [Avg. Cost]: 0.12200000137090683 | [Elapsed Time]: 18:00:47\n",
      "tensor(-0.0315, device='cuda:0') tensor(-0.0217, device='cuda:0')\n",
      "tensor(-0.0255, device='cuda:0') tensor(-0.0217, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 240 | [Avg. Reward]: 34.199520111083984 | [Avg. Cost]: 0.12167999893426895 | [Elapsed Time]: 18:04:44\n",
      "tensor(-0.0271, device='cuda:0') tensor(-0.0179, device='cuda:0')\n",
      "tensor(-0.0220, device='cuda:0') tensor(-0.0179, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 241 | [Avg. Reward]: 34.12847900390625 | [Avg. Cost]: 0.11791999638080597 | [Elapsed Time]: 18:08:41\n",
      "tensor(-0.0195, device='cuda:0') tensor(-0.0192, device='cuda:0')\n",
      "tensor(-0.0158, device='cuda:0') tensor(-0.0192, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 242 | [Avg. Reward]: 33.988800048828125 | [Avg. Cost]: 0.11919999867677689 | [Elapsed Time]: 18:12:37\n",
      "tensor(-0.0262, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "tensor(-0.0212, device='cuda:0') tensor(-0.0212, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 243 | [Avg. Reward]: 34.051239013671875 | [Avg. Cost]: 0.12116000056266785 | [Elapsed Time]: 18:16:35\n",
      "tensor(-0.0208, device='cuda:0') tensor(-0.0219, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 244 | [Avg. Reward]: 34.000118255615234 | [Avg. Cost]: 0.12188000231981277 | [Elapsed Time]: 18:20:30\n",
      "tensor(-0.0225, device='cuda:0') tensor(-0.0174, device='cuda:0')\n",
      "tensor(-0.0182, device='cuda:0') tensor(-0.0174, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 245 | [Avg. Reward]: 34.20336151123047 | [Avg. Cost]: 0.11744000017642975 | [Elapsed Time]: 18:29:00\n",
      "tensor(-0.0271, device='cuda:0') tensor(-0.0206, device='cuda:0')\n",
      "tensor(-0.0220, device='cuda:0') tensor(-0.0206, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 246 | [Avg. Reward]: 34.13296127319336 | [Avg. Cost]: 0.12064000219106674 | [Elapsed Time]: 18:32:51\n",
      "tensor(-0.0182, device='cuda:0') tensor(-0.0163, device='cuda:0')\n",
      "tensor(-0.0148, device='cuda:0') tensor(-0.0163, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 247 | [Avg. Reward]: 34.23891830444336 | [Avg. Cost]: 0.11627999693155289 | [Elapsed Time]: 18:36:43\n",
      "tensor(-0.0137, device='cuda:0') tensor(-0.0182, device='cuda:0')\n",
      "Step Len.: 1.0 \n",
      "\n",
      "[Episode]: 248 | [Avg. Reward]: 34.30815887451172 | [Avg. Cost]: 0.11823999881744385 | [Elapsed Time]: 18:40:39\n",
      "tensor(-0.0194, device='cuda:0') tensor(-0.0183, device='cuda:0')\n",
      "tensor(-0.0157, device='cuda:0') tensor(-0.0183, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 249 | [Avg. Reward]: 34.30971908569336 | [Avg. Cost]: 0.11828000098466873 | [Elapsed Time]: 18:44:36\n",
      "tensor(-0.0194, device='cuda:0') tensor(-0.0205, device='cuda:0')\n",
      "tensor(-0.0157, device='cuda:0') tensor(-0.0205, device='cuda:0')\n",
      "Step Len.: 0.9 \n",
      "\n",
      "[Episode]: 250 | [Avg. Reward]: 34.27067947387695 | [Avg. Cost]: 0.12052000313997269 | [Elapsed Time]: 18:48:31\n"
     ]
    }
   ],
   "source": [
    "cpo.train(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
